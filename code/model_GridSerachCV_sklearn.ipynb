{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification using CNN+LSTM model\n",
    "### (And hyperparameter  Grid Search using GridSearchCV from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moskaleona/anaconda2/envs/tfcpu/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback, ProgbarLogger, BaseLogger\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "from src import data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/moskaleona/alenadir/data/rawData' #'C:/Users/alena/Desktop/homed/laba/data/rawData' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.DataBuildClassifier(path_to_data).get_data([25, 33], shuffle=True, random_state=1, resample_to=128, windows=[(0.2, 0.5)],baseline_window=(0.2, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of target class: 64.027539 %\n",
      "Percentage of target class: 71.732523 %\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of target class: %f %%'%(data[33][1].mean()*100))\n",
    "print('Percentage of target class: %f %%'%(data[25][1].mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581, 39, 19)\n",
      "(581,)\n"
     ]
    }
   ],
   "source": [
    "print (data[33][0].shape)\n",
    "print (data[33][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data[33][0], data[33][1], test_size=0.2, stratify=data[33][1], random_state=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "\n",
    "class LossMetricHistory(Callback):\n",
    "    def __init__(self, validation_data=(), verbose=1):\n",
    "        super(LossMetricHistory, self).__init__()\n",
    "        self.x_val, self.y_val = validation_data\n",
    "        self.verbose = verbose\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter(\"%(message)s\")\n",
    "        console.setFormatter(formatter)\n",
    "        if len(self.logger.handlers) > 0:\n",
    "            self.logger.handlers = []\n",
    "        self.logger.addHandler(console)\n",
    "            \n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.logger.info(\"Training began\")\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = []\n",
    "        self.val_accs = []\n",
    "        self.aucs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        if self.x_val is not None and self.y_val is not None: \n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            self.val_accs.append(logs.get('val_acc'))\n",
    "            self.y_pred = self.model.predict_proba(self.x_val, verbose=0)\n",
    "            self.aucs.append(roc_auc_score(self.y_val, self.y_pred))\n",
    "            self.logger.info(\"epoch %d results: train loss = %.6f, val loss = %.6f\"%(epoch + 1, self.losses[-1], self.val_losses[-1]) + \n",
    "                             \"\\n\\t\\t\\tacc = %.6f, val acc = %.6f\"%(self.accs[-1], self.val_accs[-1]) +\n",
    "                             \"\\n\\t\\t\\tauc = %.6f\"%(self.aucs[-1]))\n",
    "        else:\n",
    "            self.logger.info(\"epoch %d results: train loss = %.6f\"%(epoch + 1, self.losses[-1]) + \n",
    "                             \"\\n\\t\\t\\tacc = %.6f\"%(self.accs[-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class CnnLstmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, loss='binary_crossentropy', n_filters=10, n_lstm=30, n_iter=150, batch_size=10,\n",
    "                 learning_rate=0.001, l1=0., l2=0.0, dropout=0., dropout_lstm=0., recurrent_dropout=0., threshold=0.5):\n",
    "        self.loss = loss\n",
    "        self.n_lstm = n_lstm\n",
    "        self.n_filters = n_filters\n",
    "        self.n_iter = n_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.dropout = dropout\n",
    "        self.dropout_lstm = dropout_lstm\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def _make_test_model(self, input_shape):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(1, input_shape=(741,), activation='sigmoid'))\n",
    "        \n",
    "    def _make_model(self, input_shape):\n",
    "        batch_input_shape = (None, input_shape[1], input_shape[2])\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv1D(self.n_filters, self.kernel_size_, batch_input_shape=batch_input_shape,\n",
    "                         activation='relu', kernel_regularizer=l1_l2(self.l1, self.l2)))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(LSTM(self.n_lstm,\n",
    "                       dropout=self.dropout_lstm, recurrent_dropout=self.recurrent_dropout))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, verbose=2):\n",
    "        # TODO: check the parameters\n",
    "        self.kernel_size_ = X_train.shape[2]\n",
    "        #self._make_test_model(X_train.shape)\n",
    "        self._make_model(X_train.shape)\n",
    "        self.optimizer_ = RMSprop(lr=self.learning_rate)\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer_, metrics=['acc'])\n",
    "\n",
    "        #self.log_ = LossMetricHistory(validation_data=(X_val, y_val))#BaseLogger()\n",
    "        self.hist_ = self.model.fit(X_train, y_train,\n",
    "                        batch_size=self.batch_size,\n",
    "                        epochs=self.n_iter) \n",
    "                        #validation_data=(X_val, y_val), verbose=verbose, callbacks=[self.log_])\n",
    "        return self.hist_\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        try:\n",
    "            getattr(self, \"kernel_size_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        '''\n",
    "        proba = self.model.predict(X)\n",
    "        return (proba > self.threshold).astype('int32')\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        try:\n",
    "            getattr(self, \"kernel_size_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        '''\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y, scoring='auc'):\n",
    "        try:\n",
    "            if scoring=='auc':\n",
    "                return roc_auc_score(y, self.predict_proba(X))\n",
    "            elif scoring=='acc':\n",
    "                return accuracy_score(y, self.predict(X))\n",
    "            else:\n",
    "                raise ValueError(message=\"No such option: '%s'. Use 'auc' or 'acc'\"%str(scoring))\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parameters_grid = {\n",
    "    'n_iter' : [100, 200, 300],\n",
    "    'l1' : [0., 0.2, 0.4, 0.6],\n",
    "    'l2' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout_lstm' : [0., 0.2, 0.4, 0.6],\n",
    "    'recurrent_dropout' : [0., 0.2, 0.4, 0.6],\n",
    "}\n",
    "'''\n",
    "parameters_grid = {\n",
    "    'n_iter' : [2,3],\n",
    "    'l1' : [0., 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CnnLstmClassifier(n_lstm=3, n_filters=2, batch_size=10)\n",
    "cv = StratifiedShuffleSplit( n_splits=2, test_size = 0.5, random_state = 108)\n",
    "gs = GridSearchCV(clf, parameters_grid, scoring=None, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.7026 - acc: 0.5560\n",
      "Epoch 2/2\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 0.6824 - acc: 0.6164\n",
      "Epoch 1/2\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.6655 - acc: 0.6121\n",
      "Epoch 2/2\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 0.6613 - acc: 0.6164\n",
      "Epoch 1/3\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.7008 - acc: 0.4957\n",
      "Epoch 2/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 0.6930 - acc: 0.5690\n",
      "Epoch 3/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 0.6809 - acc: 0.5948\n",
      "Epoch 1/3\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.6952 - acc: 0.5603\n",
      "Epoch 2/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 0.6791 - acc: 0.6164\n",
      "Epoch 3/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 0.6756 - acc: 0.6379\n",
      "Epoch 1/2\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 7.4607 - acc: 0.5733\n",
      "Epoch 2/2\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 5.0711 - acc: 0.5431\n",
      "Epoch 1/2\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 7.4470 - acc: 0.6207\n",
      "Epoch 2/2\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 4.5752 - acc: 0.6379\n",
      "Epoch 1/3\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 7.4333 - acc: 0.4871\n",
      "Epoch 2/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 4.8150 - acc: 0.5216\n",
      "Epoch 3/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 3.0144 - acc: 0.5474\n",
      "Epoch 1/3\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 7.3730 - acc: 0.5043\n",
      "Epoch 2/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 4.5968 - acc: 0.6034\n",
      "Epoch 3/3\n",
      "232/232 [==============================] - 0s 1ms/step - loss: 2.7520 - acc: 0.6207\n",
      "Epoch 1/3\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6834 - acc: 0.5819\n",
      "Epoch 2/3\n",
      "464/464 [==============================] - 1s 1ms/step - loss: 0.6708 - acc: 0.6228\n",
      "Epoch 3/3\n",
      "464/464 [==============================] - 1s 1ms/step - loss: 0.6652 - acc: 0.6358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=2, random_state=108, test_size=0.5,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=CnnLstmClassifier(batch_size=10, dropout=0.0, dropout_lstm=0.0, l1=0.0,\n",
       "         l2=0.0, learning_rate=0.001, loss='binary_crossentropy',\n",
       "         n_filters=2, n_iter=150, n_lstm=3, recurrent_dropout=0.0,\n",
       "         threshold=0.5),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_iter': [2, 3], 'l1': [0.0, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnLstmClassifier(batch_size=10, dropout=0.0, dropout_lstm=0.0, l1=0.0,\n",
      "         l2=0.0, learning_rate=0.001, loss='binary_crossentropy',\n",
      "         n_filters=2, n_iter=3, n_lstm=3, recurrent_dropout=0.0,\n",
      "         threshold=0.5)\n",
      "{'n_iter': 3, 'l1': 0.0}\n",
      "0.5127961510471416\n"
     ]
    }
   ],
   "source": [
    "print gs.best_estimator_\n",
    "print gs.best_params_\n",
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
