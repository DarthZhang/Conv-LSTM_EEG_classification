{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification using Conv-LSTM model\n",
    "Here we do hyperparameter grid search by making own GridSearch object and without using library functions or objects (such as GridSearchCV from sklearn). We need to create such an object, because it is not correct to compare neural networks by scores after a fixed number of epochs (due to overfiting and so on) and we need to plot learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moskaleona/anaconda2/envs/tfcpu/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Conv1D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "from src import data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras.backend as K\n",
    "#K.tf.device('/gpu:0')\n",
    "#K.set_session(K.tf.Session(config=K.tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../sample_data' #'/home/moskaleona/alenadir/data/rawData' #'C:/Users/alena/Desktop/homed/laba/data/rawData' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.DataBuildClassifier(path_to_data).get_data([33], shuffle=True, random_state=1, resample_to=128, windows=[(0.2, 0.5)],baseline_window=(0.2, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = data[33][0], data[33][1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[33][0], data[33][1], test_size=0.2, stratify=data[33][1], random_state=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import logging\n",
    "\n",
    "class LossMetricHistory(Callback):\n",
    "    def __init__(self, n_iter, validation_data=(None,None), verbose=1, \n",
    "                 fname_bestmodel=None, fname_lastmodel=None):\n",
    "        super(LossMetricHistory, self).__init__()\n",
    "        self.n_iter = n_iter\n",
    "        self.x_val, self.y_val = validation_data\n",
    "        self.fname_best = fname_bestmodel\n",
    "        self.fname_last = fname_lastmodel\n",
    "        if self.x_val is not None and self.y_val is not None:\n",
    "            self.validate = True\n",
    "        else:\n",
    "            self.validate = False\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter(\"%(message)s\")\n",
    "        console.setFormatter(formatter)\n",
    "        if len(self.logger.handlers) > 0:\n",
    "            self.logger.handlers = []\n",
    "        self.logger.addHandler(console)\n",
    "            \n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if self.verbose > 0:\n",
    "            self.logger.info(\"Training began\")\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = [] # accuracy scores\n",
    "        self.val_accs = [] # validation accuracy scores\n",
    "        self.aucs = []# validation ROC AUC scores\n",
    "        self.sens = []# validation sensitivity (or True Positive Rate) scores\n",
    "        self.spc = [] # validation specificity scores\n",
    "        self.thresholds = [] # Decreasing thresholds used to compute specificity and sensitivity\n",
    "        \n",
    "        self.maxauc = 0\n",
    "        self.bestepoch = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        if self.validate: \n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            self.val_accs.append(logs.get('val_acc'))\n",
    "            self.y_pred = self.model.predict_proba(self.x_val, verbose=0)\n",
    "            self.aucs.append(roc_auc_score(self.y_val, self.y_pred))\n",
    "            \n",
    "            FPR, TPR, thresholds = roc_curve(self.y_val, self.y_pred)\n",
    "            self.sens.append(TPR)\n",
    "            self.spc.append(1-FPR)\n",
    "            self.thresholds.append(thresholds)\n",
    "            \n",
    "            if self.aucs[-1] > self.maxauc:\n",
    "                self.maxauc = self.aucs[-1]\n",
    "                self.bestepoch = epoch\n",
    "                if self.fname_best is not None:\n",
    "                    self.model.save(self.fname_best)\n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                self.logger.info(\"Epoch %d/%d: train loss = %.6f, test loss = %.6f\"%(epoch+1, self.n_iter, \n",
    "                                                                    self.losses[-1],self.val_losses[-1]) + \n",
    "                                 \"\\n\\tacc = %.6f, test acc = %.6f\"%(self.accs[-1], self.val_accs[-1]) +\n",
    "                                 \"\\n\\tauc = %.6f\"%(self.aucs[-1]))\n",
    "        elif self.verbose > 0:\n",
    "            self.logger.info(\"Epoch %d/%d results: train loss = %.6f\"%(epoch+1, self.n_iter, self.losses[-1]) + \n",
    "                             \"\\n\\t\\t\\tacc = %.6f\"%(self.accs[-1]))\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.losses = np.array(self.losses)\n",
    "        if self.validate:\n",
    "            self.val_losses = np.array(self.val_losses)\n",
    "            self.scores = {}\n",
    "            self.scores['auc'] = np.array(self.aucs)\n",
    "            self.scores['acc'] = np.array(self.val_accs)\n",
    "            self.scores['sens'] = np.array(self.sens)\n",
    "            self.scores['spc'] = np.array(self.spc)\n",
    "            self.scores['thresholds'] = np.array(self.thresholds)\n",
    "        if self.fname_last is not None:\n",
    "            self.model.save(self.fname_last)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CnnLstmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, loss='binary_crossentropy', n_filters=10, n_lstm=30, n_iter=150,\n",
    "                 batch_size=10,learning_rate=0.001, l1=0., l2=0.0, dropout=0.,\n",
    "                 dropout_lstm=0., recurrent_dropout=0., threshold=0.5):\n",
    "        self.loss = loss\n",
    "        self.n_lstm = n_lstm\n",
    "        self.n_filters = n_filters\n",
    "        self.n_iter = n_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.dropout = dropout\n",
    "        self.dropout_lstm = dropout_lstm\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _make_model(self, input_shape):\n",
    "        batch_input_shape = (None, input_shape[1], input_shape[2])\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv1D(self.n_filters, self.kernel_size_, batch_input_shape=batch_input_shape,\n",
    "                         activation='relu', kernel_regularizer=l1_l2(self.l1, self.l2)))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(LSTM(self.n_lstm,\n",
    "                       dropout=self.dropout_lstm, recurrent_dropout=self.recurrent_dropout))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    def _plot_loss(self,fname=None):\n",
    "        plt.title('Learning curves')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.plot(np.arange(1, len(self.log_.losses)+1),self.log_.losses, color='tab:blue', label='train loss')\n",
    "        plt.plot(np.arange(1, len(self.log_.val_losses)+1),self.log_.val_losses, color='tab:orange', label='test loss')\n",
    "        plt.legend()\n",
    "        if fname is not None:\n",
    "            plt.savefig(fname)\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def _plot_scores(self,scoring,fname=None):\n",
    "        plt.title('Validation '+scoring)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel(scoring)\n",
    "        plt.plot(np.arange(1, len(self.log_.aucs)+1),self.log_.aucs, color='b')\n",
    "        if fname is not None:\n",
    "            plt.savefig(fname)\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, scoring='auc',n_iter=None,\n",
    "            verbose=1, plotcurves=False, fname_loss=None, fname_score=None,\n",
    "            fname_bestmodel=None, fname_lastmodel=None):\n",
    "        # TODO: check the parameters\n",
    "        if verbose > 0:\n",
    "            print(\"Training model with parameters:\", self.get_params())\n",
    "        if n_iter is not None:\n",
    "            self.n_iter = n_iter\n",
    "        \n",
    "        self.kernel_size_ = X_train.shape[2]\n",
    "        self._make_model(X_train.shape)\n",
    "        self.optimizer_ = RMSprop(lr=self.learning_rate)\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer_, metrics=['acc'])\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.log_ = LossMetricHistory(n_iter=self.n_iter, \n",
    "                                          validation_data=(X_val, y_val), verbose=verbose, \n",
    "                                          fname_bestmodel=fname_bestmodel, fname_lastmodel=fname_lastmodel)\n",
    "            self.hist_ = self.model.fit(X_train, y_train,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        epochs=self.n_iter, validation_data=(X_val, y_val),\n",
    "                                        verbose=0, callbacks=[self.log_])\n",
    "            \n",
    "            self.best_score_ = self.log_.scores[scoring].max()\n",
    "            if plotcurves:\n",
    "                self._plot_loss(fname_loss)\n",
    "                self._plot_scores(scoring, fname_score)\n",
    "        else:\n",
    "            self.log_ = LossMetricHistory(n_iter=self.n_iter)\n",
    "            self.hist_ = self.model.fit(X_train, y_train,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        epochs=self.n_iter,\n",
    "                                        verbose=verbose, callbacks=[self.log_])\n",
    "        self.fit_ = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        try:\n",
    "            getattr(self, \"fit_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifier before predicting data!\")\n",
    "        \n",
    "        proba = self.model.predict(X)\n",
    "        return (proba > self.threshold).astype('int32')\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        try:\n",
    "            getattr(self, \"fit_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifier before predicting data!\")\n",
    "        \n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y, scoring='auc'):\n",
    "        try:\n",
    "            if scoring=='auc':\n",
    "                return roc_auc_score(y, self.predict_proba(X))\n",
    "            elif scoring=='acc':\n",
    "                return accuracy_score(y, self.predict(X))\n",
    "            else:\n",
    "                raise ValueError(message=\"No such option: '%s'. Use 'auc' or 'acc'\"%str(scoring))\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "            \n",
    "    def set_model(self, model):\n",
    "        assert \\\n",
    "        str(type(model))==\"<class 'keras.models.Sequential'>\" or\\\n",
    "        str(type(model))==\"<type 'str'>\" and re.match(r'.*[^\\s]\\.hdf5$', filename),\\\n",
    "        \"Model type should be keras.models.Sequential or HDF5 file\"\n",
    "        if str(type(model))==\"<class 'keras.models.Sequential'>\": \n",
    "            self.model = model\n",
    "        else:\n",
    "            self.model = load_model(model)\n",
    "        self.n_filters = None\n",
    "        self.n_lstm = None\n",
    "        self.kernel_size_ = None\n",
    "        self.dropout = None\n",
    "        self.dropout_lstm = None\n",
    "        self.recurrent_dropout = None\n",
    "        self.fit_ = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing that everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "clf = CnnLstmClassifier(n_iter=3)\n",
    "clf.fit(X_train, y_train, X_val=X_test, y_val=y_test, verbose=2, plotcurves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "from functools import reduce\n",
    "\n",
    "class GridSearch:\n",
    "    def __init__(self, estimator, param_grid, scoring='auc',\n",
    "                 cv=None, verbose=0, plot_scores=True, refit=True):\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        self.plot_scores = plot_scores\n",
    "        self.refit = refit\n",
    "    \n",
    "    def _get_param_iterator(self):\n",
    "        \"\"\"Return ParameterGrid instance for the given param_grid\"\"\"\n",
    "        return ParameterGrid(self.param_grid)\n",
    "    \n",
    "    def _save_results(self, path, index, fold, estimator):\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        if not os.path.isdir(os.path.join(path, index)):\n",
    "            os.mkdir(os.path.join(path, index))\n",
    "        \n",
    "        path_to_results = os.path.join(path, index, fold)\n",
    "        if not os.path.isdir(path_to_results):\n",
    "            os.mkdir(path_to_results)\n",
    "        \n",
    "        os.rename(os.path.join(path,'tmp','loss.png'), os.path.join(path_to_results,'loss'+index+'.png'))\n",
    "        os.rename(os.path.join(path,'tmp','score.png'), os.path.join(path_to_results,self.scoring+index+'.png'))\n",
    "        os.rename(os.path.join(path,'tmp','model'+index+str(fold)+'.hdf5'),\n",
    "                  os.path.join(path, index, 'model'+index+str(fold)+'.hdf5'))\n",
    "        \n",
    "        params = {self.scoring:estimator.log_.scores[self.scoring],\n",
    "                'accuracy':estimator.log_.scores[self.scoring],\n",
    "                'spc':estimator.log_.scores['spc'],\n",
    "                'sens':estimator.log_.scores['sens'],\n",
    "                'thresholds':estimator.log_.scores['thresholds']}\n",
    "            \n",
    "        np.savez(os.path.join(path_to_results,'scores'+index),\n",
    "                **params)\n",
    "    \n",
    "        \n",
    "    def fit(self, X_train, y_train, X_test, y_test, groups=None, scoring='auc', path_to_results=None):\n",
    "        n_splits = cv.get_n_splits(X, y, groups)\n",
    "        candidate_params = list(self._get_param_iterator())\n",
    "        n_candidates = len(candidate_params)\n",
    "        param_names = self.param_grid.keys()\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n",
    "                  \" {2} fits\".format(n_splits, n_candidates,\n",
    "                                     n_candidates * n_splits))\n",
    "        if path_to_results is not None:\n",
    "            saveres = True\n",
    "            tmp = os.path.join(path_to_results,'tmp')\n",
    "            if not os.path.isdir(tmp):\n",
    "                os.mkdir(tmp)\n",
    "            fname_loss = os.path.join(tmp,'loss.png')\n",
    "            fname_score = os.path.join(tmp,'score.png')\n",
    "            \n",
    "        else:\n",
    "            saveres = False\n",
    "            fname_loss = None\n",
    "            fname_score = None\n",
    "            if not os.path.isdir('tmp'):\n",
    "                os.mkdir('tmp')\n",
    "            tmp = 'tmp'\n",
    "        \n",
    "        self.scores_ = [np.array([]), np.array([])]\n",
    "        #self.cv_scores_ = []\n",
    "        self.best_score_ = 0\n",
    "        idparams = 0\n",
    "        indices = []\n",
    "        with open(os.path.join(path_to_results, 'idtopars.csv'), 'w') as idp:\n",
    "            idp.write(','.join(['id']+[p for p in param_names]))\n",
    "            idp.write('\\n')\n",
    "        \n",
    "        for params in candidate_params:\n",
    "            idparams += 1\n",
    "            index='{0:04}'.format(idparams)\n",
    "            indices.append(index)\n",
    "            #self.cv_scores_.append([])\n",
    "            fold = 0\n",
    "            best_n_iters = np.array([])\n",
    "            for train, val in cv.split(X_train, y_train, groups):\n",
    "                estimator = clone(self.estimator)\n",
    "                estimator.set_params(**params)\n",
    "                estimator.fit(X_train[train], y_train[train], X_val=X_train[val], y_val=y_train[val],\n",
    "                                scoring=self.scoring, verbose=self.verbose, plotcurves=saveres,\n",
    "                                fname_loss=fname_loss, fname_score=fname_score,\n",
    "                                fname_bestmodel=os.path.join(tmp,'model'+index+str(fold)+'.hdf5'))\n",
    "                best_n_iters = np.append(best_n_iters, estimator.log_.bestepoch)\n",
    "                #self.cv_scores_[-1].append(estimator.best_score_)\n",
    "                \n",
    "                if saveres:\n",
    "                    self._save_results(path_to_results, index, str(fold), estimator)\n",
    "                with open(os.path.join(path_to_results, 'idtopars.csv'), 'a') as idp:\n",
    "                    idp.write(','.join([index]+[str(params[p]) for p in param_names]))\n",
    "                    idp.write('\\n')\n",
    "                fold += 1\n",
    "                \n",
    "            # Testing the best models for each fold on the hold-out data (1)\n",
    "            # and testing a new model (trained on all the train dataset) \n",
    "            # with the average best number of epochs on the hold-out data (2)\n",
    "            # (1)\n",
    "            preds1 = np.empty(shape=(X_test.shape[0], n_splits))\n",
    "            mean_score = 0\n",
    "            for fold in  range(n_splits):\n",
    "                if saveres:\n",
    "                    path_to_model = os.path.join(path_to_results, index, 'model'+index+str(fold)+'.hdf5')\n",
    "                else:\n",
    "                    path_to_model = os.path.join(tmp, index, 'model'+index+str(fold)+'.hdf5')\n",
    "                estimator = clone(self.estimator) \n",
    "                estimator.set_model(load_model(path_to_model))\n",
    "                estimator.set_params(**params)\n",
    "                preds1[:, fold] = estimator.predict_proba(X_test)[:,0]\n",
    "                \n",
    "            K.clear_session()\n",
    "            \n",
    "            y_pred1 = preds1.mean(axis=1)\n",
    "            \n",
    "            # (2)\n",
    "            best_n_iter = best_n_iters.mean()\n",
    "            estimator = clone(self.estimator)\n",
    "            estimator.set_params(**params)\n",
    "            estimator.fit(X_train[train], y_train[train], X_val=X_train[val], y_val=y_train[val],\n",
    "                            scoring=self.scoring, n_iter=best_n_iter, verbose=self.verbose, \n",
    "                            plotcurves=saveres,fname_loss=fname_loss, fname_score=fname_score,\n",
    "                            fname_lastmodel=os.path.join(tmp,'model'+index+'_mean.hdf5'))\n",
    "            y_pred2 = estimator.predict_proba(X_test)[:,0]\n",
    "            try:\n",
    "                if scoring=='auc':\n",
    "                    score1 = roc_auc_score(y_test, y_pred1)\n",
    "                    score2 = roc_auc_score(y_test, y_pred2)\n",
    "                elif scoring=='acc':\n",
    "                    score1 = accuracy_score(y_test, y_pred1)\n",
    "                    score2 = accuracy_score(y_test, y_pred2)\n",
    "                else:\n",
    "                    raise ValueError(message=\"No such option: '%s'. Use 'auc' or 'acc'\"%str(scoring))\n",
    "            except ValueError as err:\n",
    "                print(err)\n",
    "                \n",
    "            if saveres:\n",
    "                # (1)\n",
    "                path_to_ensemble_res = os.path.join(path_to_results, index, 'ensemble')\n",
    "                if not os.isdir(path_to_ensemble_res):\n",
    "                    os.path.join(path_to_ensemble_res)\n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
    "                np.savez(os.path.join(path_to_ensemble_res, 'ens_tpr_fpr_thres'+index), \n",
    "                        {'tpr':tpr, 'fpr':fpr, 'thresholds':thresholds})\n",
    "                plt.title('ROC curve')\n",
    "                plt.xlabel('FPR')\n",
    "                plt.ylabel('TPR')\n",
    "                plt.plot(fpr, tpr)\n",
    "                plt.savefig(os.path.join(path_to_ensemble_res, 'ROC_curve.png'))\n",
    "                plt.clf()\n",
    "                plt.cla()\n",
    "                \n",
    "                with open(os.path.join(path_to_results, 'ens_score_table.csv'), 'a') as fout:\n",
    "                    fout.write(index+','+str(score1))\n",
    "                    fout.write('\\n')\n",
    "                \n",
    "                # (2)\n",
    "                self._save_results(path_to_results, index, 'mean', estimator)\n",
    "                                 \n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred2)\n",
    "                np.savez(os.path.join(os.path.join(path_to_results, index, 'mean'), \n",
    "                                      'mean_tpr_fpr_thres'+index), \n",
    "                        {'tpr':tpr, 'fpr':fpr, 'thresholds':thresholds})\n",
    "                plt.title('ROC curve')\n",
    "                plt.xlabel('FPR')\n",
    "                plt.ylabel('TPR')\n",
    "                plt.plot(fpr, tpr)\n",
    "                plt.savefig(os.path.join(path_to_ensemble_res, 'ROC_curve.png'))\n",
    "                plt.clf()\n",
    "                plt.cla()\n",
    "                \n",
    "                with open(os.path.join(path_to_results, 'mean_score_table.csv'), 'a') as fout:\n",
    "                    fout.write(index+','+str(score2))\n",
    "                    fout.write('\\n')\n",
    "                                \n",
    "            \n",
    "            self.scores_[0] = np.append(self.scores_[0], score1)\n",
    "            self.scores_[1] = np.append(self.scores_[1], score2)\n",
    "            \n",
    "        self.best_ind_ = (self.scores_[0].argmax(), self.scores_[1].argmax())\n",
    "        self.best_score_ = (self.scores_[0][self.best_ind_[0]], self.scores_[1][self.best_ind_[1]])\n",
    "        self.best_params_ = (candidate_params[self.best_ind_[0]], candidate_params[self.best_ind_[1]])\n",
    "        \n",
    "        if saveres:\n",
    "            with open(os.path.join(path_to_results, 'ens_score_table.csv'), 'w') as fout:\n",
    "                ind = np.argsort(self.scores_[0])\n",
    "                for i in ind[::-1]:\n",
    "                    fout.write(indices[i]+','+str(self.scores_[0][i]))\n",
    "                    fout.write('\\n')\n",
    "            with open(os.path.join(path_to_results, 'mean_score_table.csv'), 'w') as fout:\n",
    "                ind = np.argsort(self.scores_[1])\n",
    "                for i in ind[::-1]:\n",
    "                    fout.write(indices[i]+','+str(self.scores_[1][i]))\n",
    "                    fout.write('\\n')\n",
    "        os.rmdir(tmp)\n",
    "        \n",
    "            \n",
    "        #self.cv_scores_ = reduce(lambda a,b: np.vstack((np.array(a),np.array(b))), self.cv_scores_)\n",
    "        #self.mean_scores_ = self.cv_scores_.mean(axis=1)\n",
    "        #self.best_score_ = self.cv_scores_.max()\n",
    "        #self.best_mean_score_ = self.mean_scores_.max()\n",
    "        #self.best_ind_ = self.mean_scores_.argmax()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.best_params_ = candidate_params[self.best_ind_]\n",
    "        if self.refit:\n",
    "            if self.verbose > 0:\n",
    "            print(\"Grid search is almost done.\\n\"\n",
    "                  \"Best score is %.6f, best mean score is %.6f.\\n\"\n",
    "                  \"Now the best estimator is training...\"%(self.best_score_, self.best_mean_score_))\n",
    "            \n",
    "            self.best_estimator_ = clone(self.estimator).set_params(**self.best_params_)\n",
    "            self.best_estimator_.fit(X,y)\n",
    "        '''\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "param_grid = {\n",
    "    'n_iter' : [100, 200, 300],\n",
    "    'l1' : [0., 0.2, 0.4, 0.6],\n",
    "    'l2' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout_lstm' : [0., 0.2, 0.4, 0.6],\n",
    "    'recurrent_dropout' : [0., 0.2, 0.4, 0.6],\n",
    "}\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_iter' : [3, 2],\n",
    "    'l1' : [0., 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "clf = CnnLstmClassifier()\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size = 0.33, random_state = 108)\n",
    "gs = GridSearch(clf, param_grid, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.671020, test loss = 0.647219\n",
      "\tacc = 0.606452, test acc = 0.603896\n",
      "\tauc = 0.603673\n",
      "Epoch 2/3: train loss = 0.607723, test loss = 0.639674\n",
      "\tacc = 0.687097, test acc = 0.623377\n",
      "\tauc = 0.608999\n",
      "Epoch 3/3: train loss = 0.566569, test loss = 0.655795\n",
      "\tacc = 0.725806, test acc = 0.649351\n",
      "\tauc = 0.588613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.700209, test loss = 0.674531\n",
      "\tacc = 0.564516, test acc = 0.597403\n",
      "\tauc = 0.505234\n",
      "Epoch 2/3: train loss = 0.630856, test loss = 0.678691\n",
      "\tacc = 0.651613, test acc = 0.636364\n",
      "\tauc = 0.504867\n",
      "Epoch 3/3: train loss = 0.590245, test loss = 0.662372\n",
      "\tacc = 0.712903, test acc = 0.636364\n",
      "\tauc = 0.553719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.682674, test loss = 0.669887\n",
      "\tacc = 0.583871, test acc = 0.610390\n",
      "\tauc = 0.526905\n",
      "Epoch 2/3: train loss = 0.603432, test loss = 0.661727\n",
      "\tacc = 0.674194, test acc = 0.629870\n",
      "\tauc = 0.550046\n",
      "Epoch 3/3: train loss = 0.578981, test loss = 0.666554\n",
      "\tacc = 0.690323, test acc = 0.655844\n",
      "\tauc = 0.536639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got numpy.float64.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-45354762dcfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%%time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-055305c1e4b1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test, groups, scoring, path_to_results)\u001b[0m\n\u001b[1;32m    129\u001b[0m                             \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_n_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                             \u001b[0mplotcurves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaveres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                             fname_lastmodel=os.path.join(tmp,'model'+index+'_mean.hdf5'))\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bfe7aeabc765>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_val, y_val, scoring, n_iter, verbose, plotcurves, fname_loss, fname_score, fname_bestmodel, fname_lastmodel)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                         verbose=0, callbacks=[self.log_])\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moskaleona/anaconda2/envs/tfcpu/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/moskaleona/anaconda2/envs/tfcpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/moskaleona/anaconda2/envs/tfcpu/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0;31m# Reset stateful metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range() integer end argument expected, got numpy.float64."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "gs.fit(X_train, y_train, X_test, y_test, path_to_results='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnLstmClassifier(batch_size=10, dropout=0.0, dropout_lstm=0.0, l1=0.0,\n",
      "         l2=0.0, learning_rate=0.001, loss='binary_crossentropy',\n",
      "         n_filters=10, n_iter=3, n_lstm=30, recurrent_dropout=0.0,\n",
      "         threshold=0.5)\n",
      "{'n_iter': 3, 'l1': 0.0}\n",
      "0.6474608224343114\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_estimator_)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
