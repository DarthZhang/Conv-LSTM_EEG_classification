{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification using Conv-LSTM model\n",
    "Here we do hyperparameter grid search by making own GridSearch object and without using library functions or objects (such as GridSearchCV from sklearn). We need to create such an object, because it is not correct to compare neural networks by scores after a fixed number of epochs (due to overfiting and so on) and we need to plot learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Conv1D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "from src import data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import keras.backend as K\n",
    "#K.tf.device('/gpu:0')\n",
    "#K.set_session(K.tf.Session(config=K.tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = '../sample_data' #'/home/moskaleona/alenadir/data/rawData' #'C:/Users/alena/Desktop/homed/laba/data/rawData' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dt.DataBuildClassifier(path_to_data).get_data([33], shuffle=True, random_state=1, resample_to=128, windows=[(0.2, 0.5)],baseline_window=(0.2, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = data[33][0], data[33][1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[33][0], data[33][1], test_size=0.2, stratify=data[33][1], random_state=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import logging\n",
    "\n",
    "class LossMetricHistory(Callback):\n",
    "    def __init__(self, n_iter, validation_data=(None,None), verbose=1, filename=None):\n",
    "        super(LossMetricHistory, self).__init__()\n",
    "        self.n_iter = n_iter\n",
    "        self.x_val, self.y_val = validation_data\n",
    "        self.filename = filename\n",
    "        if self.x_val is not None and self.y_val is not None:\n",
    "            self.validate = True\n",
    "        else:\n",
    "            self.validate = False\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter(\"%(message)s\")\n",
    "        console.setFormatter(formatter)\n",
    "        if len(self.logger.handlers) > 0:\n",
    "            self.logger.handlers = []\n",
    "        self.logger.addHandler(console)\n",
    "            \n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if self.verbose > 0:\n",
    "            self.logger.info(\"Training began\")\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = [] # accuracy scores\n",
    "        self.val_accs = [] # validation accuracy scores\n",
    "        self.aucs = []# validation ROC AUC scores\n",
    "        self.sens = []# validation sensitivity (or True Positive Rate) scores\n",
    "        self.spc = [] # validation specificity scores\n",
    "        self.thresholds = [] # Decreasing thresholds used to compute specificity and sensitivity\n",
    "        \n",
    "        self.maxauc = 0\n",
    "        self.bestepoch = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        if self.validate: \n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            self.val_accs.append(logs.get('val_acc'))\n",
    "            self.y_pred = self.model.predict_proba(self.x_val, verbose=0)\n",
    "            self.aucs.append(roc_auc_score(self.y_val, self.y_pred))\n",
    "            \n",
    "            FPR, TPR, thresholds = roc_curve(self.y_val, self.y_pred)\n",
    "            self.sens.append(TPR)\n",
    "            self.spc.append(1-FPR)\n",
    "            self.thresholds.append(thresholds)\n",
    "            \n",
    "            if self.aucs[-1] > self.maxauc:\n",
    "                self.maxauc = self.aucs[-1]\n",
    "                self.bestepoch = epoch\n",
    "                if self.filename is not None:\n",
    "                    self.model.save(self.filename)\n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                self.logger.info(\"Epoch %d/%d: train loss = %.6f, test loss = %.6f\"%(epoch+1, self.n_iter, \n",
    "                                                                    self.losses[-1],self.val_losses[-1]) + \n",
    "                                 \"\\n\\tacc = %.6f, test acc = %.6f\"%(self.accs[-1], self.val_accs[-1]) +\n",
    "                                 \"\\n\\tauc = %.6f\"%(self.aucs[-1]))\n",
    "        elif self.verbose > 0:\n",
    "            self.logger.info(\"Epoch %d/%d results: train loss = %.6f\"%(epoch+1, self.n_iter, self.losses[-1]) + \n",
    "                             \"\\n\\t\\t\\tacc = %.6f\"%(self.accs[-1]))\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.losses = np.array(self.losses)\n",
    "        if self.validate:\n",
    "            self.val_losses = np.array(self.val_losses)\n",
    "            self.scores = {}\n",
    "            self.scores['auc'] = np.array(self.aucs)\n",
    "            self.scores['acc'] = np.array(self.val_accs)\n",
    "            self.scores['sens'] = np.array(self.sens)\n",
    "            self.scores['spc'] = np.array(self.spc)\n",
    "            self.scores['thresholds'] = np.array(self.thresholds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CnnLstmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, loss='binary_crossentropy', n_filters=10, n_lstm=30, n_iter=150,\n",
    "                 batch_size=10,learning_rate=0.001, l1=0., l2=0.0, dropout=0.,\n",
    "                 dropout_lstm=0., recurrent_dropout=0., threshold=0.5):\n",
    "        self.loss = loss\n",
    "        self.n_lstm = n_lstm\n",
    "        self.n_filters = n_filters\n",
    "        self.n_iter = n_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.dropout = dropout\n",
    "        self.dropout_lstm = dropout_lstm\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _make_model(self, input_shape):\n",
    "        batch_input_shape = (None, input_shape[1], input_shape[2])\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv1D(self.n_filters, self.kernel_size_, batch_input_shape=batch_input_shape,\n",
    "                         activation='relu', kernel_regularizer=l1_l2(self.l1, self.l2)))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(LSTM(self.n_lstm,\n",
    "                       dropout=self.dropout_lstm, recurrent_dropout=self.recurrent_dropout))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    def _plot_loss(self,fname=None):\n",
    "        plt.title('Learning curves')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.plot(np.arange(1, len(self.log_.losses)+1),self.log_.losses, color='tab:blue', label='train loss')\n",
    "        plt.plot(np.arange(1, len(self.log_.val_losses)+1),self.log_.val_losses, color='tab:orange', label='test loss')\n",
    "        plt.legend()\n",
    "        if fname is not None:\n",
    "            plt.savefig(fname)\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def _plot_scores(self,scoring,fname=None):\n",
    "        plt.title('Validation '+scoring)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel(scoring)\n",
    "        plt.plot(np.arange(1, len(self.log_.aucs)+1),self.log_.aucs, color='b')\n",
    "        if fname is not None:\n",
    "            plt.savefig(fname)\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, scoring='auc',n_iter=None,\n",
    "            verbose=1, plotcurves=False, fname_loss=None, fname_score=None, fname_bestmodel=None):\n",
    "        # TODO: check the parameters\n",
    "        if verbose > 0:\n",
    "            print(\"Training model with parameters:\", self.get_params())\n",
    "        if n_iter is not None:\n",
    "            self.n_iter = n_iter\n",
    "        \n",
    "        self.kernel_size_ = X_train.shape[2]\n",
    "        self._make_model(X_train.shape)\n",
    "        self.optimizer_ = RMSprop(lr=self.learning_rate)\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer_, metrics=['acc'])\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.log_ = LossMetricHistory(n_iter=self.n_iter, \n",
    "                                          validation_data=(X_val, y_val), verbose=verbose, filename=fname_bestmodel)\n",
    "            self.hist_ = self.model.fit(X_train, y_train,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        epochs=self.n_iter, validation_data=(X_val, y_val),\n",
    "                                        verbose=0, callbacks=[self.log_])\n",
    "            \n",
    "            self.best_score_ = self.log_.scores[scoring].max()\n",
    "            if plotcurves:\n",
    "                self._plot_loss(fname_loss)\n",
    "                self._plot_scores(scoring, fname_score)\n",
    "        else:\n",
    "            self.log_ = LossMetricHistory(n_iter=self.n_iter)\n",
    "            self.hist_ = self.model.fit(X_train, y_train,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        epochs=self.n_iter,\n",
    "                                        verbose=verbose, callbacks=[self.log_])\n",
    "        self.fit_ = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        try:\n",
    "            getattr(self, \"fit_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifier before predicting data!\")\n",
    "        \n",
    "        proba = self.model.predict(X)\n",
    "        return (proba > self.threshold).astype('int32')\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        try:\n",
    "            getattr(self, \"fit_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifier before predicting data!\")\n",
    "        \n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y, scoring='auc'):\n",
    "        try:\n",
    "            if scoring=='auc':\n",
    "                return roc_auc_score(y, self.predict_proba(X))\n",
    "            elif scoring=='acc':\n",
    "                return accuracy_score(y, self.predict(X))\n",
    "            else:\n",
    "                raise ValueError(message=\"No such option: '%s'. Use 'auc' or 'acc'\"%str(scoring))\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "            \n",
    "    def set_model(self, model):\n",
    "        assert \\\n",
    "        str(type(model))==\"<class 'keras.models.Sequential'>\" or\\\n",
    "        str(type(model))==\"<type 'str'>\" and re.match(r'.*[^\\s]\\.hdf5$', filename),\\\n",
    "        \"Model type should be keras.models.Sequential or HDF5 file\"\n",
    "        if str(type(model))==\"<class 'keras.models.Sequential'>\": \n",
    "            self.model = model\n",
    "        else:\n",
    "            self.model = load_model(model)\n",
    "        self.n_filters = None\n",
    "        self.n_lstm = None\n",
    "        self.kernel_size_ = None\n",
    "        self.dropout = None\n",
    "        self.dropout_lstm = None\n",
    "        self.recurrent_dropout = None\n",
    "        self.fit_ = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing that everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.700143, test loss = 0.704361\n",
      "\tacc = 0.581897, test acc = 0.623932\n",
      "\tauc = 0.470476\n",
      "Epoch 2/3: train loss = 0.605901, test loss = 0.674746\n",
      "\tacc = 0.670259, test acc = 0.675214\n",
      "\tauc = 0.564444\n",
      "Epoch 3/3: train loss = 0.580283, test loss = 0.720637\n",
      "\tacc = 0.691810, test acc = 0.632479\n",
      "\tauc = 0.498095\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUrAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe736e2a450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe728684bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CnnLstmClassifier(batch_size=10, dropout=0.0, dropout_lstm=0.0, l1=0.0,\n",
       "         l2=0.0, learning_rate=0.001, loss='binary_crossentropy',\n",
       "         n_filters=10, n_iter=3, n_lstm=30, recurrent_dropout=0.0,\n",
       "         threshold=0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "clf = CnnLstmClassifier(n_iter=3)\n",
    "clf.fit(X_train, y_train, X_val=X_test, y_val=y_test, verbose=2, plotcurves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "from functools import reduce\n",
    "\n",
    "class GridSearch:\n",
    "    def __init__(self, estimator, param_grid, scoring='auc',\n",
    "                 cv=None, verbose=0, plot_scores=True, refit=True):\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        self.plot_scores = plot_scores\n",
    "        self.refit = refit\n",
    "    \n",
    "    def _get_param_iterator(self):\n",
    "        \"\"\"Return ParameterGrid instance for the given param_grid\"\"\"\n",
    "        return ParameterGrid(self.param_grid)\n",
    "    \n",
    "    def _save_results(self, path, index, fold, estimator):\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        if not os.path.isdir(os.path.join(path, index)):\n",
    "            os.mkdir(os.path.join(path, index))\n",
    "        \n",
    "        path_to_results = os.path.join(path, index, fold)\n",
    "        if not os.path.isdir(path_to_results):\n",
    "            os.mkdir(path_to_results)\n",
    "        \n",
    "        os.rename(os.path.join(path,'tmp','loss.png'), os.path.join(path_to_results,'loss'+index+'.png'))\n",
    "        os.rename(os.path.join(path,'tmp','score.png'), os.path.join(path_to_results,self.scoring+index+'.png'))\n",
    "        os.rename(os.path.join(path,'tmp','model'+index+str(fold)+'.hdf5'),\n",
    "                  os.path.join(path, index, 'model'+index+str(fold)+'.hdf5'))\n",
    "        \n",
    "        params = {self.scoring:estimator.log_.scores[self.scoring],\n",
    "                'accuracy':estimator.log_.scores[self.scoring],\n",
    "                'spc':estimator.log_.scores['spc'],\n",
    "                'sens':estimator.log_.scores['sens'],\n",
    "                'thresholds':estimator.log_.scores['thresholds']}\n",
    "            \n",
    "        np.savez(os.path.join(path_to_results,'scores'+index),\n",
    "                **params)\n",
    "    \n",
    "        \n",
    "    def fit(self, X_train, y_train, X_test, y_test, groups=None, scoring='auc', path_to_results=None):\n",
    "        n_splits = cv.get_n_splits(X, y, groups)\n",
    "        candidate_params = list(self._get_param_iterator())\n",
    "        n_candidates = len(candidate_params)\n",
    "        param_names = self.param_grid.keys()\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n",
    "                  \" {2} fits\".format(n_splits, n_candidates,\n",
    "                                     n_candidates * n_splits))\n",
    "        if path_to_results is not None:\n",
    "            saverez = True\n",
    "            tmp = os.path.join(path_to_results,'tmp')\n",
    "            if not os.path.isdir(tmp):\n",
    "                os.mkdir(tmp)\n",
    "            fname_loss = os.path.join(tmp,'loss.png')\n",
    "            fname_score = os.path.join(tmp,'score.png')\n",
    "            \n",
    "        else:\n",
    "            saverez = False\n",
    "            fname_loss = None\n",
    "            fname_score = None\n",
    "            if not os.path.isdir('tmp'):\n",
    "                os.mkdir('tmp')\n",
    "            tmp = 'tmp'\n",
    "        \n",
    "        self.cv_scores_ = np.array([])\n",
    "        #self.cv_scores_ = []\n",
    "        self.best_score_ = 0\n",
    "        idparams = 0\n",
    "        indices = []\n",
    "        with open(os.path.join(path_to_results, 'idtopars.csv'), 'w') as idp:\n",
    "            idp.write(','.join(['id']+[p for p in param_names]))\n",
    "            idp.write('\\n')\n",
    "        \n",
    "        for params in candidate_params:\n",
    "            idparams += 1\n",
    "            index='{0:04}'.format(idparams)\n",
    "            indices.append(index)\n",
    "            #self.cv_scores_.append([])\n",
    "            fold = 0\n",
    "            best_n_iters = np.array([])\n",
    "            for train, val in cv.split(X_train, y_train, groups):\n",
    "                estimator = clone(self.estimator)\n",
    "                estimator.set_params(**params)\n",
    "                estimator.fit(X_train[train], y_train[train], X_val=X_train[val], y_val=y_train[val],\n",
    "                                scoring=self.scoring, verbose=self.verbose, plotcurves=saverez,\n",
    "                                fname_loss=fname_loss, fname_score=fname_score,\n",
    "                                fname_bestmodel=os.path.join(tmp,'model'+index+str(fold)+'.hdf5'))\n",
    "                best_n_iters = np.append(best_n_iters, estemator.log_.bestepoch)\n",
    "                #self.cv_scores_[-1].append(estimator.best_score_)\n",
    "                \n",
    "                if saverez:\n",
    "                    self._save_results(path_to_results, index, str(fold), estimator)\n",
    "                with open(os.path.join(path_to_results, 'idtopars.csv'), 'a') as idp:\n",
    "                    idp.write(','.join([index]+[str(params[p]) for p in param_names]))\n",
    "                    idp.write('\\n')\n",
    "                fold += 1\n",
    "                \n",
    "            # Testing the best models for each fold on the hold-out data (1)\n",
    "            # and testing a new model (trained on all the train dataset) \n",
    "            # with the average best number of epochs on the hold-out data (2)\n",
    "            # (1)\n",
    "            preds1 = np.empty(shape=(X_test.shape[0], n_splits))\n",
    "            mean_score = 0\n",
    "            for fold in  range(n_splits):\n",
    "                if saverez:\n",
    "                    path_to_model = os.path.join(path_to_results, index, 'model'+index+str(fold)+'.hdf5')\n",
    "                else:\n",
    "                    path_to_model = os.path.join(tmp, index, 'model'+index+str(fold)+'.hdf5')\n",
    "                estimator = clone(self.estimator) \n",
    "                estimator.set_model(load_model(path_to_model))\n",
    "                estimator.set_params(**params)\n",
    "                preds1[:, fold] = estimator.predict_proba(X_test)[:,0]\n",
    "                \n",
    "            K.clear_session()\n",
    "            \n",
    "            y_pred1 = preds1.mean(axis=1)\n",
    "            \n",
    "            # (2) In process...\n",
    "            best_n_iter = best_n_iters.mean()\n",
    "            estimator = clone(self.estimator)\n",
    "            estimator.set_params(**params)\n",
    "            estimator.fit(X_train[train], y_train[train], X_val=X_train[val], y_val=y_train[val],\n",
    "                            scoring=self.scoring, n_iter=best_n_iter, verbose=self.verbose, \n",
    "                            plotcurves=saverez,fname_loss=???fname_loss, fname_score=???fname_score,\n",
    "                            fname_best(last???)model=???os.path.join(tmp,'model'+index+str(fold)+'.hdf5'))\n",
    "            try:\n",
    "                if scoring=='auc':\n",
    "                    score = roc_auc_score(y_test, y_pred)\n",
    "                elif scoring=='acc':\n",
    "                    score = accuracy_score(y_test, y_pred)\n",
    "                else:\n",
    "                    raise ValueError(message=\"No such option: '%s'. Use 'auc' or 'acc'\"%str(scoring))\n",
    "            except ValueError as err:\n",
    "                print(err)\n",
    "                \n",
    "            if saverez:\n",
    "                with open(os.path.join(path_to_results, 'score_table.csv'), 'a') as fout:\n",
    "                    fout.write(index+','+str(score))\n",
    "                    fout.write('\\n')\n",
    "                \n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "                np.savez(os.path.join(path_to_results, index, 'final_tpr_fpr_thres'+index), \n",
    "                        {'tpr':tpr, 'fpr':fpr, 'thresholds':thresholds})\n",
    "                plt.title('ROC curve')\n",
    "                plt.xlabel('FPR')\n",
    "                plt.ylabel('TPR')\n",
    "                plt.plot(fpr, tpr)\n",
    "                plt.savefig(os.path.join(path_to_results, index, 'ROC_curve.png'))\n",
    "                plt.clf()\n",
    "                plt.cla()\n",
    "            \n",
    "            self.cv_scores_ = np.append(self.cv_scores_, score)\n",
    "            \n",
    "        self.best_ind_ = self.cv_scores_.argmax()\n",
    "        self.best_score_ = self.cv_scores_[self.best_ind_]\n",
    "        self.best_params_ = candidate_params[self.best_ind_]\n",
    "        \n",
    "        if saverez:\n",
    "            with open(os.path.join(path_to_results, 'score_table.csv'), 'w') as fout:\n",
    "                ind = np.argsort(self.cv_scores_)\n",
    "                for i in ind[::-1]:\n",
    "                    fout.write(indices[i]+','+str(self.cv_scores_[i]))\n",
    "                    fout.write('\\n')\n",
    "        os.rmdir(tmp)\n",
    "        \n",
    "            \n",
    "        #self.cv_scores_ = reduce(lambda a,b: np.vstack((np.array(a),np.array(b))), self.cv_scores_)\n",
    "        #self.mean_scores_ = self.cv_scores_.mean(axis=1)\n",
    "        #self.best_score_ = self.cv_scores_.max()\n",
    "        #self.best_mean_score_ = self.mean_scores_.max()\n",
    "        #self.best_ind_ = self.mean_scores_.argmax()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.best_params_ = candidate_params[self.best_ind_]\n",
    "        if self.refit:\n",
    "            if self.verbose > 0:\n",
    "            print(\"Grid search is almost done.\\n\"\n",
    "                  \"Best score is %.6f, best mean score is %.6f.\\n\"\n",
    "                  \"Now the best estimator is training...\"%(self.best_score_, self.best_mean_score_))\n",
    "            \n",
    "            self.best_estimator_ = clone(self.estimator).set_params(**self.best_params_)\n",
    "            self.best_estimator_.fit(X,y)\n",
    "        '''\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "param_grid = {\n",
    "    'n_iter' : [100, 200, 300],\n",
    "    'l1' : [0., 0.2, 0.4, 0.6],\n",
    "    'l2' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout_lstm' : [0., 0.2, 0.4, 0.6],\n",
    "    'recurrent_dropout' : [0., 0.2, 0.4, 0.6],\n",
    "}\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_iter' : [3, 2],\n",
    "    'l1' : [0., 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "clf = CnnLstmClassifier()\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size = 0.33, random_state = 108)\n",
    "gs = GridSearch(clf, param_grid, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.665459, test loss = 0.663981\n",
      "\tacc = 0.606452, test acc = 0.623377\n",
      "\tauc = 0.557943\n",
      "Epoch 2/3: train loss = 0.625858, test loss = 0.668998\n",
      "\tacc = 0.683871, test acc = 0.629870\n",
      "\tauc = 0.557576\n",
      "Epoch 3/3: train loss = 0.610198, test loss = 0.669568\n",
      "\tacc = 0.680645, test acc = 0.597403\n",
      "\tauc = 0.554637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.698701, test loss = 0.666905\n",
      "\tacc = 0.538710, test acc = 0.610390\n",
      "\tauc = 0.566758\n",
      "Epoch 2/3: train loss = 0.634900, test loss = 0.639810\n",
      "\tacc = 0.648387, test acc = 0.655844\n",
      "\tauc = 0.595041\n",
      "Epoch 3/3: train loss = 0.607467, test loss = 0.631236\n",
      "\tacc = 0.664516, test acc = 0.616883\n",
      "\tauc = 0.606244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 0.691356, test loss = 0.644965\n",
      "\tacc = 0.632258, test acc = 0.610390\n",
      "\tauc = 0.585124\n",
      "Epoch 2/3: train loss = 0.618339, test loss = 0.648907\n",
      "\tacc = 0.674194, test acc = 0.655844\n",
      "\tauc = 0.578145\n",
      "Epoch 3/3: train loss = 0.583220, test loss = 0.668970\n",
      "\tacc = 0.680645, test acc = 0.577922\n",
      "\tauc = 0.552801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 2, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/2: train loss = 0.701807, test loss = 0.640706\n",
      "\tacc = 0.535484, test acc = 0.603896\n",
      "\tauc = 0.623508\n",
      "Epoch 2/2: train loss = 0.637578, test loss = 0.640535\n",
      "\tacc = 0.632258, test acc = 0.623377\n",
      "\tauc = 0.620937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 2, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/2: train loss = 0.693211, test loss = 0.677308\n",
      "\tacc = 0.587097, test acc = 0.590909\n",
      "\tauc = 0.526722\n",
      "Epoch 2/2: train loss = 0.621965, test loss = 0.677240\n",
      "\tacc = 0.687097, test acc = 0.603896\n",
      "\tauc = 0.520845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 2, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.0, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/2: train loss = 0.659916, test loss = 0.648646\n",
      "\tacc = 0.587097, test acc = 0.642857\n",
      "\tauc = 0.548393\n",
      "Epoch 2/2: train loss = 0.615282, test loss = 0.669243\n",
      "\tacc = 0.670968, test acc = 0.597403\n",
      "\tauc = 0.490725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.2, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 24.247075, test loss = 15.179784\n",
      "\tacc = 0.603226, test acc = 0.642857\n",
      "\tauc = 0.615978\n",
      "Epoch 2/3: train loss = 9.803215, test loss = 5.227187\n",
      "\tacc = 0.625806, test acc = 0.597403\n",
      "\tauc = 0.614141\n",
      "Epoch 3/3: train loss = 2.889493, test loss = 1.244672\n",
      "\tacc = 0.606452, test acc = 0.642857\n",
      "\tauc = 0.599265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.2, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 24.987036, test loss = 15.853807\n",
      "\tacc = 0.554839, test acc = 0.642857\n",
      "\tauc = 0.540496\n",
      "Epoch 2/3: train loss = 10.287341, test loss = 5.525069\n",
      "\tacc = 0.645161, test acc = 0.649351\n",
      "\tauc = 0.577227\n",
      "Epoch 3/3: train loss = 2.997478, test loss = 1.309677\n",
      "\tacc = 0.664516, test acc = 0.629870\n",
      "\tauc = 0.643159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 3, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.2, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/3: train loss = 24.788476, test loss = 15.794339\n",
      "\tacc = 0.587097, test acc = 0.597403\n",
      "\tauc = 0.510927\n",
      "Epoch 2/3: train loss = 10.362221, test loss = 5.689438\n",
      "\tacc = 0.658065, test acc = 0.649351\n",
      "\tauc = 0.508540\n",
      "Epoch 3/3: train loss = 3.118126, test loss = 1.404012\n",
      "\tacc = 0.632258, test acc = 0.616883\n",
      "\tauc = 0.515335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 2, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.2, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/2: train loss = 24.789808, test loss = 15.836555\n",
      "\tacc = 0.616129, test acc = 0.610390\n",
      "\tauc = 0.385308\n",
      "Epoch 2/2: train loss = 10.273459, test loss = 5.466824\n",
      "\tacc = 0.641935, test acc = 0.623377\n",
      "\tauc = 0.584206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 2, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.2, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/2: train loss = 24.432069, test loss = 15.398808\n",
      "\tacc = 0.570968, test acc = 0.623377\n",
      "\tauc = 0.601469\n",
      "Epoch 2/2: train loss = 10.010812, test loss = 5.355765\n",
      "\tacc = 0.635484, test acc = 0.629870\n",
      "\tauc = 0.677502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model with parameters:', {'loss': 'binary_crossentropy', 'recurrent_dropout': 0.0, 'n_iter': 2, 'learning_rate': 0.001, 'batch_size': 10, 'n_filters': 10, 'l2': 0.0, 'n_lstm': 30, 'l1': 0.2, 'threshold': 0.5, 'dropout_lstm': 0.0, 'dropout': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training began\n",
      "Epoch 1/2: train loss = 25.754223, test loss = 16.528179\n",
      "\tacc = 0.480645, test acc = 0.623377\n",
      "\tauc = 0.476400\n",
      "Epoch 2/2: train loss = 10.783096, test loss = 5.810811\n",
      "\tacc = 0.645161, test acc = 0.623377\n",
      "\tauc = 0.519008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 3.1 s, total: 1min 54s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GridSearch instance at 0x7f176c85e680>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs.fit(X_train, y_train, X_test, y_test, path_to_results='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnLstmClassifier(batch_size=10, dropout=0.0, dropout_lstm=0.0, l1=0.0,\n",
      "         l2=0.0, learning_rate=0.001, loss='binary_crossentropy',\n",
      "         n_filters=10, n_iter=3, n_lstm=30, recurrent_dropout=0.0,\n",
      "         threshold=0.5)\n",
      "{'n_iter': 3, 'l1': 0.0}\n",
      "0.6474608224343114\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_estimator_)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
