{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification using Conv-LSTM model\n",
    "Here we do hyperparameter grid search by making own GridSearch object and without using library functions or objects (such as GridSearchCV from sklearn). We need to create such an object, because it is not correct to compare neural networks by scores after a fixed number of epochs (due to overfiting and so on) and we need to plot learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moskaleona/anaconda2/envs/tfcpu/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback, ProgbarLogger, BaseLogger\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "from src import data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/moskaleona/alenadir/data/rawData' #'C:/Users/alena/Desktop/homed/laba/data/rawData' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt.DataBuildClassifier(path_to_data).get_data([25, 33], shuffle=True, random_state=1, resample_to=128, windows=[(0.2, 0.5)],baseline_window=(0.2, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = data[33][0], data[33][1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(data[33][0], data[33][1], test_size=0.2, stratify=data[33][1], random_state=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import logging\n",
    "\n",
    "class LossMetricHistory(Callback):\n",
    "    def __init__(self, n_iter, validation_data=(None,None), verbose=1):\n",
    "        super(LossMetricHistory, self).__init__()\n",
    "        self.n_iter = n_iter\n",
    "        self.x_val, self.y_val = validation_data\n",
    "        if self.x_val is not None and self.y_val is not None:\n",
    "            self.validate = True\n",
    "        else:\n",
    "            self.validate = False\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter(\"%(message)s\")\n",
    "        console.setFormatter(formatter)\n",
    "        if len(self.logger.handlers) > 0:\n",
    "            self.logger.handlers = []\n",
    "        self.logger.addHandler(console)\n",
    "            \n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if self.verbose > 0:\n",
    "            self.logger.info(\"Training began\")\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = [] # accuracy scores\n",
    "        self.val_accs = [] # validation accuracy scores\n",
    "        self.aucs = []# validation ROC AUC scores\n",
    "        self.sens = []# validation sensitivity (or True Positive Rate) scores\n",
    "        self.spc = [] # validation specificity scores\n",
    "        self.thresholds = [] # Decreasing thresholds used to compute specificity and sensitivity\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        if self.validate: \n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            self.val_accs.append(logs.get('val_acc'))\n",
    "            self.y_pred = self.model.predict_proba(self.x_val, verbose=0)\n",
    "            self.aucs.append(roc_auc_score(self.y_val, self.y_pred))\n",
    "            \n",
    "            FPR, TPR, thresholds = roc_curve(self.y_val, self.y_pred)\n",
    "            self.sens.append(TPR)\n",
    "            self.spc.append(1-FPR)\n",
    "            self.thresholds.append(thresholds)\n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                self.logger.info(\"Epoch %d/%d results: train loss = %.6f, test loss = %.6f\"%(epoch+1, self.n_iter, \n",
    "                                                                    self.losses[-1],self.val_losses[-1]) + \n",
    "                                 \"\\n\\t\\t\\tacc = %.6f, test acc = %.6f\"%(self.accs[-1], self.val_accs[-1]) +\n",
    "                                 \"\\n\\t\\t\\tauc = %.6f\"%(self.aucs[-1]))\n",
    "        elif self.verbose > 0:\n",
    "            self.logger.info(\"Epoch %d/%d results: train loss = %.6f\"%(epoch+1, self.n_iter, self.losses[-1]) + \n",
    "                             \"\\n\\t\\t\\tacc = %.6f\"%(self.accs[-1]))\n",
    "    def on_train_end(self, logs={}):\n",
    "        if self.validate:\n",
    "            self.scores = {}\n",
    "            self.scores['auc'] = self.aucs\n",
    "            self.scores['acc'] = self.val_accs\n",
    "            self.scores['sens'] = self.sens\n",
    "            self.scores['spc'] = self.spc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class CnnLstmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, loss='binary_crossentropy', n_filters=10, n_lstm=30, n_iter=150, batch_size=10,\n",
    "                 learning_rate=0.001, l1=0., l2=0.0, dropout=0., dropout_lstm=0., recurrent_dropout=0., threshold=0.5):\n",
    "        self.loss = loss\n",
    "        self.n_lstm = n_lstm\n",
    "        self.n_filters = n_filters\n",
    "        self.n_iter = n_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.dropout = dropout\n",
    "        self.dropout_lstm = dropout_lstm\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _make_model(self, input_shape):\n",
    "        batch_input_shape = (None, input_shape[1], input_shape[2])\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv1D(self.n_filters, self.kernel_size_, batch_input_shape=batch_input_shape,\n",
    "                         activation='relu', kernel_regularizer=l1_l2(self.l1, self.l2)))\n",
    "        self.model.add(Dropout(self.dropout))\n",
    "        self.model.add(LSTM(self.n_lstm,\n",
    "                       dropout=self.dropout_lstm, recurrent_dropout=self.recurrent_dropout))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    def _plot_loss():\n",
    "        pass\n",
    "    \n",
    "    def _plot_scores():\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, scoring='auc', verbose=1):\n",
    "        # TODO: check the parameters\n",
    "        if verbose > 0:\n",
    "            print \"Training model with parameters:\", self.get_params\n",
    "        self.kernel_size_ = X_train.shape[2]\n",
    "        self._make_model(X_train.shape)\n",
    "        self.optimizer_ = RMSprop(lr=self.learning_rate)\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer_, metrics=['acc'])\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.log_ = LossMetricHistory(n_iter=self.n_iter, \n",
    "                                          validation_data=(X_val, y_val), verbose=verbose)\n",
    "            self.hist_ = self.model.fit(X_train, y_train,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        epochs=self.n_iter, validation_data=(X_val, y_val),\n",
    "                                        verbose=0, callbacks=[self.log_])\n",
    "            self.best_score_ = self.log_.scores[scoring].max()\n",
    "        else:\n",
    "            self.log_ = LossMetricHistory(n_iter=self.n_iter)\n",
    "            self.hist_ = self.model.fit(X_train, y_train,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        epochs=self.n_iter,\n",
    "                                        verbose=verbose, callbacks=[self.log_])\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        try:\n",
    "            getattr(self, \"kernel_size_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        '''\n",
    "        proba = self.model.predict(X)\n",
    "        return (proba > self.threshold).astype('int32')\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        try:\n",
    "            getattr(self, \"kernel_size_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        '''\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y, scoring='auc'):\n",
    "        try:\n",
    "            if scoring=='auc':\n",
    "                return roc_auc_score(y, self.predict_proba(X))\n",
    "            elif scoring=='acc':\n",
    "                return accuracy_score(y, self.predict(X))\n",
    "            else:\n",
    "                raise ValueError(message=\"No such option: '%s'. Use 'auc' or 'acc'\"%str(scoring))\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing that everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CnnLstmClassifier(n_iter=3)\n",
    "clf.fit(X_train, y_train, X_val=X_val, y_val=y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import clone\n",
    "from functools import reduce\n",
    "\n",
    "class GridSearch:\n",
    "    def __init__(self, estimator, param_grid, scoring=None,\n",
    "                 cv=None, verbose=0, plot_scores=True):\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        self.plot_scores = plot_scores\n",
    "    \n",
    "    def _get_param_iterator(self):\n",
    "        \"\"\"Return ParameterGrid instance for the given param_grid\"\"\"\n",
    "        return ParameterGrid(self.param_grid)\n",
    "        \n",
    "    def fit(self, X, y, groups=None):\n",
    "        n_splits = cv.get_n_splits(X, y, groups)\n",
    "        candidate_params = list(self._get_param_iterator())\n",
    "        n_candidates = len(candidate_params)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n",
    "                  \" {2} fits\".format(n_splits, n_candidates,\n",
    "                                     n_candidates * n_splits))\n",
    "        \n",
    "        self.cv_scores_ = []\n",
    "        for params in candidate_params:\n",
    "            self.cv_scores_.append([])\n",
    "            for train, test in cv.split(X, y, groups):\n",
    "                estimator = clone(self.estimator)\n",
    "                estimator.set_params(**params)\n",
    "                estimator.fit(X[train], y[train], X_val=X[test], y_val=y[test],\n",
    "                              scoring=self.scoring, verbose=self.verbose)\n",
    "                self.cv_scores_[-1].append(estimator.best_score_)\n",
    "        \n",
    "        self.cv_scores_ = reduce(lambda a,b: np.append(np.array(a),np.array(b),axis=0), self.cv_scores_)\n",
    "        self.mean_scores_ = self.cv_scores_.mean(axis=1)\n",
    "        self.best_score_ = self.cv_scores_.max()\n",
    "        self.best_mean_score_ = self.mean_scores_.max()\n",
    "        self.best_ind_ = self.mean_scores_.argmax()\n",
    "        if self.verbose > 0:\n",
    "            print(\"Grid search is almost done. \\n\"\n",
    "                  \"Best score is %.6f, best mean score is %.6f\"\n",
    "                  \"Now the best estimator is training...\"%(self.best_score_, best_mean_score_))\n",
    "        self.best_params_ = candidate_params[self.best_ind_]\n",
    "        self.best_estimator_ = clone(self.estimator).set_params(self.best_params_)\n",
    "        self.best_estimator_.fit(X,y)\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "param_grid = {\n",
    "    'n_iter' : [100, 200, 300],\n",
    "    'l1' : [0., 0.2, 0.4, 0.6],\n",
    "    'l2' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout' : [0., 0.2, 0.4, 0.6],\n",
    "    'dropout_lstm' : [0., 0.2, 0.4, 0.6],\n",
    "    'recurrent_dropout' : [0., 0.2, 0.4, 0.6],\n",
    "}\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_iter' : [2,3],\n",
    "    'l1' : [0., 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "model = CnnLstmClassifier()\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size = 0.33, random_state = 108)\n",
    "gs = GridSearch(model, param_grid, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
